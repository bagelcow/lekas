---
layout: post
title: Video representation of what our mind sees
tags: neuroscience
---

Have you ever seen those science fiction movies where you can clearly see what they are thinking about,
almost like a thought bubble popping up next to their head where a picture or a series of pictures is shown?
That is pretty much what Zijiao Chen, Jiaxin Qing and Juan Helen Zhu have been working on and the results are astonishing.

Long story short, they grab brain signals and convert them into images! That sounds crazy by itself but now imagine the following scenarion:
A person is watching a video, let's say, a person walking in the park during the day. You proceed to feed an AI model continuous fMRI data and it **manages** to represent the video with astonishing accuracy. **This. Is. Insane.** Moreover, they were able to do it with consumer available GPUs (an rtx 3090). 

You can read more about it on their website here: <https://mind-video.com/>.